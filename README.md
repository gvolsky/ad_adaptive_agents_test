### ad_adaptive_agents_test
Test assignment for “Adaptive Agents” x AIRI.

Для генерации данных и обучения моделей запустить `train.py`.

Вопросы по статье:

1. Интересно адаптировать подход для мультигентного обучения и проверить, насколько он хорошо справляется там. Наиболее интересно было бы увидеть кооперацию агентов в какой-то простой среде.
2. Как хорошо обучить модель на зашумленных средах (и хорошо ли она сама по себе обучается в таком случае, и на сколько больше нужно будет для этого примеров)? Для этого хотелось бы адаптировать подход с бисимуляцией (или адаптировать сам трансформер для этого подхода).

Оба вопроса я решить не успел :(

Интересные статьи:
1. Mastering Diverse Domains through World Models: статья про Dreamer V3, алгоритм с моделью мира, которая позволяет планировать действия и уменьшает количество взаимодействий с реальной средой. Мне больше нравится сама идея модели мира, но тут это всё выливается в очень эффективный алгоритм, который превосходит специализированные подходы на очень большом множестве задач. А еще это первый алгоритм, который научился собирать алмазы в майнкрафте с нуля:)

2. Learning Invariant Representations for Reinforcement Learning without Reconstruction: авторы берут метрику бисимуляции (метрика на MDP, которая, по сути, аггрегирует состояния по их поведенческой эквивалентности. Два состояния похожи, если возможные будущие награды и следующие состояния похожи) и адаптируют ее для использования в глубоком обучении. Данный подход позволяет получить информативные представления наблюдений в зашумленных средах и значительно превосходит методы реконструкции, контрастного обучения и т.д. Идея красивая, и имеет под собой довольно старый фундамент в виде статьи 2005 года.

3. In-context Reinforcement Learning with Algorithm Distillation: эта статья и идея останется у меня в памяти надолго). В данной работе авторы обучают трансформер на траекториях обучения других агентов. В результате получается модель, которая работает не только лучше, но и справляется с ранне невиданными окружениями (удивительно).

Бисимуляция отлично работает в дримере и ее можно адаптировать к его категориальным распределениям (и это работает еще лучше). Но алгоритм с ней сходится довольно медленно. Хотелось бы подумать, как улучшить подход с бисимуляцией, чтобы исправить это.
Также существует довольно много метрик сравнения POMDP. Хотелось бы разобраться, как их адаптировать к глубокому обучению, и выяснить, в каких ситуациях какие из них будут работать лучше.